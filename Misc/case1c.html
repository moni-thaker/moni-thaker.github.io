<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
  <title>Case Study 1: Choices</title>
  	<link rel="stylesheet" href="../styles/mystyles.css">
  </head>

<body>
<!-- Site navigation menu -->

<ul class="navbar">
  <li><a href="../index.html">Home</a>
  <li><a href="topic.html">Topic</a>

	<li class="dropdown">
	<a href="#">Opportunities</a>
    <div class="dropdown-content">
      <a href="case1.html">Case Study 1</a>
      <a href="case2.html">Case Study 2</a>
      <a href="case3.html">Case Study 3</a>

	<li class="dropdown">
	<a href="#">Risks</a>
	<div class="dropdown-content">
	  <a href="case1r.html">Case Study 1</a>
      <a href="case2r.html">Case Study 2</a>

	<li class="dropdown">
	<a href="#">Choices</a>
	<div class="dropdown-content">
		<a href="case1c.html">Case Study 1</a>
		<a href="case2c.html">Case Study 2</a>

	<li><a href="ethics.html">Ethical Reflections</a>
	<li><a href="references.html">References</a>

	<li class="dropdown">
	<a href="#">Process Support</a>
	<div class="dropdown-content">
		<a href="team-formation.html">Team Formation</a>
		<a href="proposal.html">Topic Proposal</a>
		<a href="evaluation.html">Peer Evaluation</a>
		<a href="meetings.html">Meeting Minutes</a>
		<a href="portfolio.html">Project Portfolio</a>
		<a href="rubric.html">Assessment Rubric</a>
		<a href="guidelines.html">Guideline Conformance</a>
</ul>

<!-- Main content -->
<h1>Case Study 1: Games</h1>
<h1>Choices</h1><br>

<p><b>Poker & Chess:</b></p>
<p>
AI creators such as DeepMind have also teamed up with chess grandmasters in order to restore some of the human art to chess. A good option for the future would be to continue to work with grandmaster players to create more chess ‘bots’ modelled after human players. For example, there are alternative modes to chess engines that are taught to play the game in the specific style of popular grandmaster players such as Magnus Carlsen and Hikaru Nakamura. The player will play against an idea that uses strategies and moves it’s human counterpart would make. This would help improve the calculated and ‘soulless’ feeling chess engines are known for and push them more towards human-like play. </p>
<p>
Another option would be to put further resources into the development of better anti-cheat detection to combat the unethical uses of AI in the gaming field. Multiple companies that produce chess engines are working on better cheat detection themselves, which is promising as they have direct access to information on how their own engines operate. With the sudden boom in online chess and online tournaments the need for robust cheat detection is at an all-time high and is being forced to rapidly improve in attempts to preserve the competitive integrity of the game.</p>
<p>
Gaming AI that utilise machine learning are constantly evolving, the future of the field is very promising with each new engine that has emerged within recent years is quickly able to surpass its predecessors, soon there will be AI developed into a state that is even more efficient than currently available, with more opportunities and upsides along with a reduced number of potential risks. We can see how self-taught AI’s have progressed in the gaming field through the examples below:
</p>
<p>
&nbsp&nbsp;&nbsp;- Deep Blue started off as a ‘brute force’ algorithm which searched through millions of possible moves per second to find an advantageous position. In comparison AlphaZero did not use this brute force approach and instead studied a vast number of chess games &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and repeatedly played games against constantly improving iterations of itself.
</p>
<p>
&nbsp&nbsp;&nbsp;- Stockfish (made through machine learning) was the previous strongest chess engine in the world and the champion among other AI. AlphaZero was able to defeat stockfish after only 4 hours of machine learning (self-play), making it the current strongest engine &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;available, being more efficient than other engines as it searches fewer board positions on average. 
</p>
<p>
&nbsp&nbsp;&nbsp;- Libratus was the first competitive poker AI, being able to play 2-player poker, it used 100 CPUs to operate. Pluribus is a 6-player poker AI that was built on top of an improved version of the Libratus algorithm while needing much less computing power to play &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;matches, using 2 CPUs (in comparison to 100) to play hands roughly twice as fast as humans (20 seconds). 
</p>

<br>

<!-- Sign and date the page, it's only polite! -->
<address>Made 6th June 2021<br>
  by Monitosh Thaker</address>
 
</body>
</html>